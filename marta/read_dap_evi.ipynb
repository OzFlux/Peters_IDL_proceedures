{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "FUNCTION read_dap_evi,url,sites\n",
    "; open the DAP file\n",
    " evi_file = ncdf_open(url)\n",
    "; get the latitude and longitude resolutions from the global attributes\n",
    " ncdf_attget,evi_file,\"geospatial_lat_resolution\",lat_res,/global\n",
    " ncdf_attget,evi_file,\"geospatial_lon_resolution\",lon_res,/global\n",
    "; get the time variable\n",
    " time_id = ncdf_varid(evi_file,\"time\")\n",
    " ncdf_varget,evi_file,time_id,time\n",
    " nrecs = n_elements(time)\n",
    "; and the time variable units attribute\n",
    " ncdf_attget,evi_file,time_id,\"units\",value\n",
    " time_units = string(value)\n",
    "; get the year, month and day from the time units string\n",
    " result = strsplit(time_units,\" \",/extract)\n",
    " ymd = strsplit(result[2],\"-\",/extract)\n",
    "; get the hour, minute and seconds\n",
    " hms = strsplit(result[3],\":\",/extract)\n",
    "; get the Julian date from the netCDF time\n",
    " jul_time = time + JulDay(fix(ymd[1]),fix(ymd[2]),fix(ymd[0]),0,0,0)\n",
    "; ... and get the year, month, day etc from the Julian date\n",
    " CalDat, jul_time, month, day, year, hour, minute, second\n",
    ";print, year[-1], month[-1], day[-1], hour[-1], minute[-1], second[-1]\n",
    "; get the latitude and longitude variables from the netCDF file\n",
    " lat_id = ncdf_varid(evi_file,\"latitude\")\n",
    " ncdf_varget,evi_file,lat_id,latitude\n",
    " lon_id = ncdf_varid(evi_file,\"longitude\")\n",
    " ncdf_varget,evi_file,lon_id,longitude\n",
    "; NOTE: evi is dimensioned as [longitude,latitude,time]\n",
    ";                          eg [19160,14902,365]\n",
    " nsites = n_elements(sites.name)\n",
    " for i=0,nsites-1 do begin\n",
    "  print,\"Processing site: \",sites.name[i]\n",
    "; get the latitude and longitude indices\n",
    "   lat_index = fix(((latitude[0]-sites.latitude[i])/lat_res)+0.5)\n",
    "   if sites.longitude[i]<0 then sites.longitude[i] = float(360) + sites.longitude[i]\n",
    "   lon_index = fix(((sites.longitude[i]-longitude[0])/lon_res)+0.5)\n",
    "; get the offset and count for the data subset\n",
    "   offset = [lon_index-1,lat_index-1,0]\n",
    "   count = [3,3,nrecs]\n",
    "; and now get the EVI data\n",
    "   evi_id = ncdf_varid(evi_file,\"evi\")\n",
    "   ncdf_varget,evi_file,evi_id,evi,offset=offset,count=count\n",
    "; create the data structure\n",
    "   new = {name:sites.name[i],year:year,month:month,day:day,$\n",
    "          hour:hour,minute:minute,second:second,$\n",
    "          evi:evi}\n",
    "; add this structure to the array\n",
    "   if i eq 0 then data = replicate(new,nsites) else data[i] = new\n",
    " endfor\n",
    "; close the netCDF file\n",
    " ncdf_close,evi_file\n",
    "; return the data structure\n",
    " return,data\n",
    "END"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "sites = {name:[\"Calperum\",\"Sturt Plains\",\"Whroo\"],$\n",
    "         latitude:[-34.00206,-17.15090,-36.67305],$\n",
    "         longitude:[140.58912,133.35055,145.02621]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "; define the DAP URL and the file name\n",
    "dap_path = \"http://www.auscover.org.au/thredds/dodsC/auscover/lpdaac-aggregates/c5/v2-nc4/aust/\"\n",
    "evi_file = \"MOD13Q1.005/MOD13Q1.aggregated.aust.005.enhanced_vegetation_index.ncml\"\n",
    "; get the full URL and open the netCDF file\n",
    "evi_url = dap_path+evi_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing site: Calperum\r\n",
      "Processing site: Sturt Plains\r\n",
      "Processing site: Whroo\r\n"
     ]
    }
   ],
   "source": [
    "data = read_dap_evi(evi_url,sites)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "for i=0,n_elements(data)-1 do begin\n",
    " nrecs = n_elements(data[i].year)\n",
    "; get the decimal year for plotting\n",
    " julian_date = JulDay(data[i].month,data[i].day,data[i].year,$\n",
    "                      data[i].hour,data[i].minute,data[i].second)\n",
    " doy = julian_date - JulDay(1,1,data[i].year)\n",
    " diy = intarr(nrecs)\n",
    " diy = 365\n",
    " idx = where((data[i].year mod 4) eq 0,count)\n",
    " diy[idx] = 366\n",
    " ydy = data[i].year + doy/diy + data[i].hour/(24*diy) + data[i].minute/(24*60*diy)\n",
    " window,i\n",
    " plot,ydy,data[i].evi[1,1,*],max_value=1.0,min_value=-0.2,$\n",
    "      xrange=[2000,2017],xtickinterval=1,$\n",
    "      xtitle=\"Years\",ytitle=\"EVI\",$\n",
    "      title=sites.name[i]\n",
    "endfor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "evi_file = ncdf_open(evi_url)\n",
    "ncdf_attget,evi_file,\"geospatial_lat_resolution\",lat_res,/global\n",
    "ncdf_attget,evi_file,\"geospatial_lon_resolution\",lon_res,/global\n",
    "time_id = ncdf_varid(evi_file,\"time\")\n",
    "ncdf_varget,evi_file,time_id,time\n",
    "nrecs = n_elements(time)\n",
    "ncdf_attget,evi_file,time_id,\"units\",value\n",
    "time_units = string(value)\n",
    "result = strsplit(time_units,\" \",/extract)\n",
    "ymd = strsplit(result[2],\"-\",/extract)\n",
    "hms = strsplit(result[3],\":\",/extract)\n",
    "jul_time = time + JulDay(fix(ymd[1]),fix(ymd[2]),fix(ymd[0]),0,0,0)\n",
    "CalDat, jul_time, month, day, year, hour, minute, second\n",
    "lat_id = ncdf_varid(evi_file,\"latitude\")\n",
    "ncdf_varget,evi_file,lat_id,latitude\n",
    "lon_id = ncdf_varid(evi_file,\"longitude\")\n",
    "ncdf_varget,evi_file,lon_id,longitude\n",
    "nsites = n_elements(sites.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for i=0,nsites-1 do begin\n",
    "  print,\"Processing site: \",sites.name[i]\n",
    "; get the latitude and longitude indices\n",
    "  lat_index = fix(((latitude[0]-sites.latitude[i])/lat_res)+0.5)\n",
    "  if sites.longitude[i]<0 then sites.longitude[i] = float(360) + sites.longitude[i]\n",
    "  lon_index = fix(((sites.longitude[i]-longitude[0])/lon_res)+0.5)\n",
    "; get the offset and count for the data subset\n",
    "  offset = [lon_index-1,lat_index-1,0]\n",
    "  count = [3,3,nrecs]\n",
    "; and now get the EVI data\n",
    "  evi_id = ncdf_varid(evi_file,\"evi\")\n",
    "  ncdf_varget,evi_file,evi_id,evi,offset=offset,count=count\n",
    "; create the data structure\n",
    "  new = {name:sites.name[i],year:year,month:month,day:day,$\n",
    "         hour:hour,minute:minute,second:second,$\n",
    "         evi:evi}\n",
    "; add this structure to the array\n",
    "  if i eq 0 then data = replicate(new,nsites) else data[i] = new\n",
    "endfor\n",
    "; close the netCDF file\n",
    "ncdf_close,evi_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "IDL",
   "language": "IDL",
   "name": "idl"
  },
  "language_info": {
   "codemirror_mode": "idl",
   "file_extension": ".pro",
   "mimetype": "text/x-idl",
   "name": "idl"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
